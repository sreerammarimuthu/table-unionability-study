# Table-Unionability-Study

Welcome to the companion repository for our research paper titled: “Humans, Machine Learning, and Language Models in Union: A Cognitive Study on Table Unionability” 
#### Status Update: Published at ACM SIGMOD HILDA '25, June 22–27, 2025, Berlin, Germany


- `ACM Publication` - https://dl.acm.org/doi/10.1145/3736733.3736740    
- `ACM Kudos Article` - https://www.growkudos.com/publications/10.1145%25252F3736733.3736740/reader    
- `Preprint` - https://arxiv.org/abs/2506.12990    

## Description
This repository provides open access to selected data samples, feature annotations, and supporting materials used in our research study. The research explores how human metacognition, machine learning models, and large language models (LLMs) interact when determining the unionability of relational tables, highlighting both interpretability and performance trade-offs in Human-in-the-loop systems. This work lays the groundwork for advancing research in human-in-the-loop, AI, data discovery, and the interpretability of large language models.

## Contents
`data/`   
- `sample_data_v1q1.csv` - A sample of annotated response data from a selected question from the research study, provided for transparency.   

`features/`   
- `feature_summary.md` - Detailed descriptions of features, feature-engineering logic, definitions and groupings of each Aggregated Feature subsets used in the study.    

`results/`  
- `tables/` - Tabular outputs referenced in the paper, including metrics, comparisons, and model performance breakdowns.     
- `figures/` - Visualizations referenced in the paper, of key findings from the study, including accuracy & reported confidence trends with time, and the aggregated feature subset performances.   

> Note:
This paper and repo presents a summary of our preliminary results from analysis, and we aim to expand this research further in future work.
